{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep NLP - Word Embeddings\n",
    "\n",
    "Think back to NLP as we've understood it so far.\n",
    "\n",
    "If we've had some luck with NLP modeling, likely with a NaiveBayes algorithm, we were able to illustrate some correlations between words and some other feature of interest.\n",
    "\n",
    "But to whatever extent that our models were able to make connections and pick up on correlations, they did this *without any understanding of the **meaning** of the words in question*.\n",
    "\n",
    "Let's think for a minute about words and objective meanings!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make sense of meaning for computational purposes by thinking about meaning in terms of similarity, i.e. thinking about meaning *holistically*.\n",
    "\n",
    "Q. Is there any precedent for this way of thinking about meaning? <br/>\n",
    "A. [Yes](https://plato.stanford.edu/entries/meaning-holism/#ArgForMeaHol)\n",
    "\n",
    "So what will this look like for us?\n",
    "\n",
    "*Remember cosine similarity?*\n",
    "\n",
    "$\\rightarrow$We'll have much the same idea here: Associate each word with values along particular dimensions in a multi-dimensional space. If we had a dimension for *softness*, for example, then pillows and marshmallows would score higher on it than rocks and bricks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/3a/32a1edf4f335eba0873021a7ddb3230f05dedd2b5450960118b402ca0771/gensim-3.8.0-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.7MB 1.4MB/s eta 0:00:01 0% |▎                               | 174kB 1.5MB/s eta 0:00:17    29% |█████████▌                      | 7.4MB 3.3MB/s eta 0:00:06\n",
      "\u001b[?25hCollecting smart-open>=1.7.0 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/c0/25d19badc495428dec6a4bf7782de617ee0246a9211af75b302a2681dea7/smart_open-1.8.4.tar.gz (63kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 4.7MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.3 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from gensim) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from gensim) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: boto>=2.32 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from smart-open>=1.7.0->gensim) (1.9.224)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from requests->smart-open>=1.7.0->gensim) (2019.6.16)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from boto3->smart-open>=1.7.0->gensim) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from boto3->smart-open>=1.7.0->gensim) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.224 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from boto3->smart-open>=1.7.0->gensim) (1.12.224)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.224->boto3->smart-open>=1.7.0->gensim) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /Users/flatironschool/anaconda3/envs/learn/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.224->boto3->smart-open>=1.7.0->gensim) (0.14)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/flatironschool/Library/Caches/pip/wheels/5f/ea/fb/5b1a947b369724063b2617011f1540c44eb00e28c3d2ca8692\n",
      "Successfully built smart-open\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.8.0 smart-open-1.8.4\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Gensim? See [here](https://en.wikipedia.org/wiki/Gensim) and [here](https://radimrehurek.com/gensim/). But, basically, gensim is a package with lots of topic-modeling and NLP tools, inlcuding Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the data [here!](https://drive.google.com/file/d/0BwT5wj_P7BKXb2hfM3d2RHU1ckE/view) (Just click 'Download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the data\n",
    "\n",
    "import json\n",
    "\n",
    "with open('JEOPARDY_QUESTIONS1.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the datatype of our data\n",
    "type(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "216930"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the length\n",
    "len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'category': 'HISTORY',\n",
       " 'air_date': '2004-12-31',\n",
       " 'question': \"'For the last 8 years of his life, Galileo was under house arrest for espousing this man's theory'\",\n",
       " 'value': '$200',\n",
       " 'answer': 'Copernicus',\n",
       " 'round': 'Jeopardy!',\n",
       " 'show_number': '4680'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the first element in our list\n",
    "data[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many words do we have in our first question?\n",
    "\n",
    "len(data[0]['question'].split(sep=' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3169994"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's count the total number of\n",
    "# clue words we have.\n",
    "\n",
    "sum([len(i['question'].split(sep=' ')) for i in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec requires that our text have the form of a list\n",
    "# of 'sentences', where each sentence is itself a list of\n",
    "# words. How can we put our _Jeopardy!_ clues in that shape?\n",
    "import string\n",
    "\n",
    "text= []\n",
    "for clue in data:\n",
    "    sentence=clue['question'].translate(str.maketrans('','',\n",
    "                                                     string.punctuation)).split(' ')   #replace the punctuation with nothing \n",
    "    new_sent = []\n",
    "    for word in sentence:\n",
    "        new_sent.append(word.lower())\n",
    "    text.append(new_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['for',\n",
       " 'the',\n",
       " 'last',\n",
       " '8',\n",
       " 'years',\n",
       " 'of',\n",
       " 'his',\n",
       " 'life',\n",
       " 'galileo',\n",
       " 'was',\n",
       " 'under',\n",
       " 'house',\n",
       " 'arrest',\n",
       " 'for',\n",
       " 'espousing',\n",
       " 'this',\n",
       " 'mans',\n",
       " 'theory']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check the new structure of our first clue\n",
    "text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing the model is simply a matter of\n",
    "# instantiating a Word2Vec object. Word2Vec trains a NN but we will use the words that are built not the NN itself.\n",
    "\n",
    "model = gensim.models.Word2Vec(text, sg=1)    #sg:skipgram, two models inside word2vec. one tries to predict single word most associated w context of words\n",
    "#skipgram starts w a single word and predicts words in that context . this is based on measuring nearness (words that appear near eachother in a sentence)\n",
    "#features is basically like topics\n",
    "\n",
    "#CBOW is the opposite of sg. starts w context and predicts word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continuous Bag of Words vs. Skipgram\n",
    "\n",
    "<a href=\"https://www.researchgate.net/figure/Illustration-of-the-Skip-gram-and-Continuous-Bag-of-Word-CBOW-models_fig1_281812760\"><img src=\"https://www.researchgate.net/profile/Wang_Ling/publication/281812760/figure/fig1/AS:613966665486361@1523392468791/Illustration-of-the-Skip-gram-and-Continuous-Bag-of-Word-CBOW-models.png\" alt=\"Illustration of the Skip-gram and Continuous Bag-of-Word (CBOW) models.\"/></a>\n",
    "\n",
    "[More on Skipgram](https://towardsdatascience.com/word2vec-skip-gram-model-part-1-intuition-78614e4d6e0b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11337425, 15849970)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To train, call 'train()'!\n",
    "\n",
    "model.train(text, total_examples=model.corpus_count,\n",
    "           epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3169994"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking word  count\n",
    "\n",
    "model.corpus_total_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2179959 , -0.13832371,  0.82045907, -0.09228509, -0.31157538,\n",
       "        0.0558117 ,  0.31941363,  0.13714567,  0.18510565, -0.18914342,\n",
       "        0.20846863,  0.19939539,  0.17979723, -0.08736508,  0.7754108 ,\n",
       "       -0.05262485,  0.49912634, -0.6519212 ,  0.02689071,  0.11322739,\n",
       "        0.02308858,  0.20876797, -0.6626779 , -0.21118072, -0.5116142 ,\n",
       "       -0.15118527, -0.2473922 ,  0.2358805 , -0.12133547,  0.17606536,\n",
       "       -0.36533666, -0.16933222,  0.27797   ,  0.15719958, -0.2768855 ,\n",
       "        0.32499468, -0.58233935,  0.01879555, -0.8135983 ,  0.02875136,\n",
       "       -0.0355689 , -0.41054052, -0.6825258 ,  0.2764217 ,  0.4702477 ,\n",
       "       -0.4349774 , -0.27470565,  0.10966807, -0.12253669,  0.46156558,\n",
       "       -0.26079467, -0.19115892, -0.10137106, -0.28267348,  0.00846066,\n",
       "        0.28400433, -0.16284879,  0.21241169,  0.4398918 , -0.33026662,\n",
       "       -0.0697035 , -0.41292527,  0.1949021 ,  0.00706244,  0.28849742,\n",
       "        0.3122224 , -0.035186  ,  0.56784433, -0.14559768,  0.38837126,\n",
       "        0.06105255, -0.42483747, -0.32690236,  0.2700348 , -0.03619486,\n",
       "        0.00217758,  0.2537319 , -0.09930537,  0.7273773 ,  0.05454724,\n",
       "        0.2848282 , -0.4335171 ,  0.50987387,  0.45548123,  0.04625761,\n",
       "        0.18646777, -0.06234394, -0.10501578, -0.1040632 , -0.37498325,\n",
       "        0.21110731, -0.35378027, -0.03917984, -0.52926874,  0.5989785 ,\n",
       "       -0.36815786, -0.21022823,  0.07746062,  0.02595785, -0.5916682 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The '.wv' attribute stores the word vectors\n",
    "\n",
    "model.wv['apple']   #this is apple represented as linear combination of themes (features or topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82045907"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The vectors are keyed by the words\n",
    "model.wv['apple'].max()    #cant get the words in that feature , it is built out of words though\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.wv methods\n",
    "#### 'most_similar()' and 'similarity()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pottery', 0.7091644406318665),\n",
       " ('neoclassical', 0.7081478238105774),\n",
       " ('decorative', 0.7044602036476135),\n",
       " ('fastener', 0.6931874752044678),\n",
       " ('chippendale', 0.6854918599128723),\n",
       " ('ceramic', 0.680397629737854),\n",
       " ('fasteners', 0.6780710816383362),\n",
       " ('accessory', 0.6768207550048828),\n",
       " ('cabriole', 0.6768094897270203),\n",
       " ('nouveau', 0.6759829521179199)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('furniture')   #the numbers are output of cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6321034"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('furniture', 'jewelry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dog', 0.7162733674049377),\n",
       " ('cheetah', 0.7162524461746216),\n",
       " ('shorthaired', 0.7084864377975464),\n",
       " ('carnivore', 0.7036651372909546),\n",
       " ('parrot', 0.6998318433761597),\n",
       " ('hound', 0.6978839635848999),\n",
       " ('pup', 0.6911518573760986),\n",
       " ('scavenger', 0.6882691383361816),\n",
       " ('feline', 0.6873884201049805),\n",
       " ('pachyderm', 0.6840150356292725)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What's most similar to 'cat'?\n",
    "\n",
    "model.wv.most_similar(positive='cat')   #the numbers are output of cosine similarity, positive is most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('themselves', -0.06060933321714401),\n",
       " ('peoples', -0.06555520743131638),\n",
       " ('tonight', -0.0809701681137085),\n",
       " ('19', -0.0884326696395874),\n",
       " ('jews', -0.0942421406507492),\n",
       " ('poor', -0.09581827372312546),\n",
       " ('fans', -0.10032132267951965),\n",
       " ('hearts', -0.10156692564487457),\n",
       " ('guest', -0.10171807557344437),\n",
       " ('gods', -0.1039452999830246)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(negative='cat')   #the dissimilar, absolute numbers matter. not the sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('throne', 0.3153429627418518),\n",
       " ('empress', 0.27299660444259644),\n",
       " ('nun', 0.24938170611858368),\n",
       " ('monarch', 0.24484051764011383),\n",
       " ('duchess', 0.24148623645305634),\n",
       " ('reign', 0.23693794012069702),\n",
       " ('heir', 0.2345750480890274),\n",
       " ('prince', 0.22962161898612976),\n",
       " ('isabella', 0.2274600863456726),\n",
       " ('athena', 0.22651103138923645)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try the familiar example: King - Man + Woman = Queen\n",
    "\n",
    "model.wv.most_similar(positive=['king', 'woman'],\n",
    "                     negative='man')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sophocles', 0.7530242800712585),\n",
       " ('shakespeares', 0.7390450835227966),\n",
       " ('euripides', 0.7144793272018433),\n",
       " ('falstaff', 0.7142761945724487),\n",
       " ('moliere', 0.6936957836151123),\n",
       " ('shaws', 0.6876543164253235),\n",
       " ('shakespearean', 0.6849218010902405),\n",
       " ('ibsen', 0.684044361114502),\n",
       " ('romeo', 0.6758466958999634),\n",
       " ('rur', 0.6730616688728333)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shakespeare\n",
    "model.wv.most_similar('shakespeare')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('kinnear', 0.8410297632217407),\n",
       " ('steely', 0.7922472357749939),\n",
       " ('dwayne', 0.78643798828125),\n",
       " ('abduljabbar', 0.7844822406768799),\n",
       " ('hamlisch', 0.7826417684555054),\n",
       " ('bebe', 0.7811517119407654),\n",
       " ('gehrig', 0.7807881832122803),\n",
       " ('waterstona', 0.7800036072731018),\n",
       " ('connelly', 0.7775446176528931),\n",
       " ('walston', 0.7745929956436157)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Greg\n",
    "\n",
    "model.wv.most_similar('greg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dc', 0.8387752771377563),\n",
       " ('arlington', 0.6481685042381287),\n",
       " ('dca', 0.6466912031173706),\n",
       " ('dcs', 0.6350167989730835),\n",
       " ('newseum', 0.6256836652755737),\n",
       " ('p3', 0.6181975603103638),\n",
       " ('delaware', 0.6124393939971924),\n",
       " ('virginia', 0.6111010909080505),\n",
       " ('washingtons', 0.6036571264266968),\n",
       " ('missouri', 0.6002857089042664)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Washington\n",
    "\n",
    "model.wv.most_similar('washington', topn=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3626155"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('seattle', 'washington')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'doesnt_match()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['breakfast','lunch','food', 'frog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bad'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(['good','bad','indifferent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'closer_than()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prince', 'kings', 'iii', 'throne', 'ruler', 'iv', 'ix', 'haakon', 'olaf']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which words are closer to 'king' than 'queen' is?\n",
    "\n",
    "model.wv.closer_than('king','queen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'distance()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this it will make more sense to\n",
    "# normalize our vectors.\n",
    "\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('king', 'king')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43866634368896484"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.distance('joy', 'happiness')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'evaluate_word_analogies()'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out [this text file](https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "relatives = model.wv.evaluate_word_analogies('https://raw.githubusercontent.com/nicholas-leonard/word2vec/master/questions-words.txt')[1][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relatives['correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relatives['incorrect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BOY', 'GIRL', 'BROTHER', 'SISTER'),\n",
       " ('BOY', 'GIRL', 'DAD', 'MOM'),\n",
       " ('BOY', 'GIRL', 'FATHER', 'MOTHER'),\n",
       " ('BOY', 'GIRL', 'HE', 'SHE'),\n",
       " ('BOY', 'GIRL', 'HIS', 'HER')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatives['correct'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BOY', 'GIRL', 'BROTHERS', 'SISTERS'),\n",
       " ('BOY', 'GIRL', 'GRANDFATHER', 'GRANDMOTHER'),\n",
       " ('BOY', 'GIRL', 'GRANDPA', 'GRANDMA'),\n",
       " ('BOY', 'GIRL', 'GRANDSON', 'GRANDDAUGHTER'),\n",
       " ('BOY', 'GIRL', 'GROOM', 'BRIDE')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relatives['incorrect'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
